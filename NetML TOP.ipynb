{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Baseline Quickstart for NetML-Competition 2020\n",
    "\n",
    "### * Loads datasets, plots confusion matrix, prints evaluation metrics on validation set and create submission JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import time as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from utils.helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create submissions\n",
    "def do_submit(clf, test_set, scaler, class_label_pair, filepath):\n",
    "    Xtest, ids = get_submission_data(test_set)\n",
    "    X_test_scaled = scaler.transform(Xtest)\n",
    "    print(\"Predicting on {} ...\".format(test_set.split('/')[-1]))\n",
    "    predictions = clf.predict(X_test_scaled)\n",
    "    make_submission(predictions, ids, class_label_pair, filepath)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify only this cell:\n",
    "# Note: anno = \"mid\" is valid ONLY with non-vpn2016 dataset\n",
    "###\n",
    "dataset = \"./data/NetML\" # or \"./data/CICIDS2017\" or \"./data/non-vpn2016\"\n",
    "anno = \"top\" # or \"mid\" or \"fine\"\n",
    "submit = \"both\" # or \"test-std\" or \"test-challenge\"\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables\n",
    "training_set = dataset+\"/2_training_set\"\n",
    "training_anno_file = dataset+\"/2_training_annotations/2_training_anno_\"+anno+\".json.gz\"\n",
    "test_set = dataset+\"/1_test-std_set\"\n",
    "challenge_set = dataset+\"/0_test-challenge_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for the results\n",
    "time_ = t.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "save_dir = os.getcwd() + '/results/' + time_\n",
    "os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training set ...\n",
      "Reading 2_training_set.json.gz\n"
     ]
    }
   ],
   "source": [
    "# Get training data in np.array format\n",
    "Xtrain, ytrain, class_label_pair, Xtrain_ids = get_training_data(training_set, training_anno_file)\n",
    "\n",
    "# Split validation set from training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(Xtrain, ytrain,\n",
    "                                                test_size=0.2, \n",
    "                                                random_state=42,\n",
    "                                                stratify=ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get name of each class to display in confusion matrix\n",
    "class_names = list(sorted(class_label_pair.keys()))\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('rfc',\n",
       "                                RandomForestClassifier(n_estimators=125,\n",
       "                                                       n_jobs=-1,\n",
       "                                                       random_state=42)),\n",
       "                               ('dtc', DecisionTreeClassifier(random_state=42)),\n",
       "                               ('dt',\n",
       "                                MLPClassifier(early_stopping=True, max_iter=400,\n",
       "                                              random_state=42))],\n",
       "                   final_estimator=ExtraTreesClassifier(n_estimators=125,\n",
       "                                                        n_jobs=-1,\n",
       "                                                        random_state=42),\n",
       "                   n_jobs=-1, passthrough=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train RF Model\n",
    "print(\"Training the model ...\")\n",
    "\n",
    "MLP = MLPClassifier(random_state=42, max_iter=400, early_stopping=True)\n",
    "DT = DecisionTreeClassifier(random_state = 42)\n",
    "ET = ExtraTreesClassifier(n_estimators=125, random_state=42, n_jobs = -1)\n",
    "RF = RandomForestClassifier(n_estimators=125, random_state=42, n_jobs = -1, max_features=\"auto\")\n",
    "\n",
    "\n",
    "eclf = StackingClassifier(estimators=[('rfc',RF), ('dtc', DT), ('mlp', MLP)],final_estimator=ET ,n_jobs=-1, passthrough=True)\n",
    "eclf.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eclf\n",
      "Training Score: \t0.99871\n",
      "Validation Score: \t0.99840\n"
     ]
    }
   ],
   "source": [
    "# Output accuracy of classifier\n",
    "print(\"eclf\")\n",
    "print(\"Training Score: \\t{:.5f}\".format(eclf.score(X_train_scaled, y_train)))\n",
    "print(\"Validation Score: \\t{:.5f}\".format(eclf.score(X_val_scaled, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Confusion Matrix\n",
    "ypred = eclf.predict(X_val_scaled)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plot_confusion_matrix(directory=save_dir, y_true=y_val, y_pred=ypred, \n",
    "                        classes=class_names, \n",
    "                        normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading submission set ...\n",
      "Reading 1_test-std_set.json.gz\n",
      "Predicting on 1_test-std_set ...\n",
      "Submission file is created as ./results/20210428-071903/submission_test-std.json\n",
      "\n",
      "Loading submission set ...\n",
      "Reading 0_test-challenge_set.json.gz\n",
      "Predicting on 0_test-challenge_set ...\n",
      "Submission file is created as ./results/20210428-071903/submission_test-challenge.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make submission with JSON format\n",
    "if submit == \"test-std\" or submit == \"both\":\n",
    "    do_submit(eclf, test_set, scaler, class_label_pair, save_dir+\"/submission_test-std.json\")\n",
    "if submit == \"test-challenge\" or submit == \"both\":\n",
    "    do_submit(eclf, challenge_set, scaler, class_label_pair, save_dir+\"/submission_test-challenge.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
